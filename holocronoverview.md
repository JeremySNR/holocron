Launching an AI-Powered, Open-Source Notion-Style Knowledge Base Product Brief Core Value Proposition Our proposed knowledge base combines Notion’s intuitive, block-based editing with a local-first, privacy-centric architecture and deeply integrated AI. The core value proposition is a self-hosted or offline-first workspace that gives users full control of their data while leveraging AI for smarter knowledge management. Unlike proprietary tools, everything runs either locally or on servers you control, ensuring data ownership and privacy by design. At the same time, built-in AI features (semantic search, summarization, Q&A) supercharge productivity by making information retrieval and content creation faster and easier. In short, this product offers the convenience of Notion’s all-in-one note-taking and database experience, augmented by AI and uncompromising on privacy – a combination not available in existing solutions. Primary & Secondary User Personas Primary personas include: - Developers & Technical Teams: who need a self-hosted wiki or project hub with rich docs, code snippets, and the ability to extend or integrate with developer tools. They value open-source flexibility and may contribute plugins or code. - Knowledge Workers & Researchers: (academics, analysts, writers) who build large personal knowledge bases or wikis. They need powerful search (including semantic/AI search) and summarization to tame information overload. Privacy is important if notes contain sensitive data. - Small Teams & Startups: seeking a collaborative workspace like Notion for project management and documentation, but on their own infrastructure. They want real-time collaboration and sharing without third-party cloud storage. Secondary personas might include: - Students & Lifelong Learners: who want a “second brain” app for notes and study materials, with AI help for summarizing lectures or generating flashcards. - Open-Source Enthusiasts: hobbyist note-takers and open-source community members who prefer tools they can self-host, tweak, and trust. They might contribute to the project or build custom plugins. - Privacy-Conscious Enterprises: organizations with strict data policies (e.g. law firms, healthcare, research labs) that need an internal knowledge base with modern features but self-hosted for compliance. By addressing both individual power-users and collaborative team scenarios, the product can grow virally: individuals adopt it for personal use and then advocate for it at work, or vice versa. This dual appeal sets a foundation for a broad user base. MVP Scope: Key Features vs. Deferred Features For the minimum viable product (MVP), we focus on essential functionality that delivers immediate user value and showcases the unique advantages: Rich Block-Based Editor: A Notion-style WYSIWYG editor supporting text blocks, headings, checklists, bullet lists, toggle sections, code blocks with syntax highlight, tables, and embedded images/files. Users can freely drag-and-drop to reorder content or convert one block type to another. Slash commands (/) allow inserting new block types or invoking AI actions. Page Organization & Linking: Ability to create pages and sub-pages (nested hierarchy) and link or reference pages easily. This addresses basic content structuring that some early open-source clones lacked (for example, AppFlowy initially did not support nesting subpages\[1\]). The MVP will ensure users can nest and reorganize pages in a tree, a core expectation for Notion-like tools. Search (Keyword & Semantic): Basic full-text search across pages, plus semantic search powered by AI embeddings. The MVP will index page content so users can query in natural language or by concept and get relevant results – a significant differentiator over current tools. For example, searching “meeting outcomes from last quarter” should find a note even if it doesn’t contain those exact words, using AI to understand context. AI Assistance Built-In: Integration of a few key AI features out-of-the-box. MVP candidates include: “Ask AI” or Summarize: Users can highlight text or an entire page and invoke an AI summary in-place. This addresses info overload by condensing long notes\[2\]. Natural Language Q&A: A chatbot-like assistant that can answer questions using the content of the knowledge base (e.g. “What did we decide about feature X in our notes?”). This requires semantic search + generation, likely leveraging an online API or local model. Content Generation: Optional commands like “/brainstorm” or “/continue writing” that use AI to help create content (this may be limited in MVP to avoid scope bloat, but at least one generation use-case could be included). Local-First Data Storage: All content is saved locally (e.g. in an encrypted database or plain files on disk) so the app works offline fully. Users do not need to rely on cloud servers for core use. This aligns with the “data privacy first” ethos\[3\]. For teams, a self-hosted server would enable sync, but an individual’s data can stay 100% local if they prefer. Basic Collaboration: Real-time collaboration in MVP may be limited (perhaps editing by one user at a time or manual sync), but we plan for multi-user in the architecture. At minimum, MVP allows exporting or sharing pages (e.g. via link or file) to test the virality loop. Full concurrent editing can be deferred if necessary, but a straightforward way to share content is included (like one-click export to Markdown/PDF or a read-only web link). Cross-Platform Desktop: Provide desktop apps for major OS (Windows, macOS, Linux) so users can install easily. The app will also run in the browser (especially for the self-hosted web version), but an installable app with offline capability is a key selling point. Mobile support will be deferred (acknowledging that some existing projects lost points for no mobile apps\[4\]\[5\]). Deferred features (for post-MVP) include: - Advanced Databases & Views: Notion’s more complex database features (relations, rollups, formulas) and fancy views (calendar, gallery) will be scoped out of MVP. Instead, MVP might offer simple table or board as a page type for basic structured data. More advanced database functionality can be added once the core is stable. - Whiteboard/Canvas: A free-form whiteboard (like Miro or AFFiNE’s whiteboard mode) is not in MVP. This can be a future differentiator, but to keep scope manageable we’ll start with document-focused features. AFFiNE’s inclusion of drawing canvases is cool\[6\], but we’ll defer that until our editor and databases are solid. - Third-Party Integrations: Connections to external services (Google Drive, Slack, calendar sync, etc.) are postponed. Many open-source Notion alternatives don’t have these initially (AFFiNE and AppFlowy both lack Google/Slack integrations\[4\]\[7\]). We’ll focus on our core app first, and allow integrations later via plugins or APIs. - Mobile Applications: Native mobile apps or fully optimized responsive mobile UI will come after MVP. We will design the web UI to be responsive enough for viewing on mobile, but a polished mobile experience (with touch optimizations, offline mobile support, etc.) will be subsequent. This addresses a known gap where AFFiNE currently has no mobile apps\[4\]. - Enterprise Admin Features: things like user admin panels, permission management for teams, SSO integration – these are important for wider adoption but can wait. Initially, a small team can use it without granular permissions (or using simple workspace sharing). As we attract more teams, we’ll build out these controls. - Plugin Marketplace: While the architecture will support plugins from day one, a UI for browsing/installing community plugins or templates can be rolled out after some plugins have been created. The plugin API should be in MVP (so developers can start extending the product), but the polished “app store” experience can wait. By concentrating on core note-taking, basic tables, and integrated AI, the MVP will be impressive yet achievable. Non-essentials are deferred to ensure we nail the fundamentals and provide a smooth, bug-free user experience early on. Differentiation from AFFiNE, AppFlowy, Outline, Logseq (Notion Alternatives) Our product enters a space with several open-source or privacy-focused Notion alternatives, but it will stand out through a blend of design, technology, and philosophy: Versus AFFiNE: AFFiNE is a promising open-source Notion/Miro hybrid, but it’s still evolving. It mirrors Notion’s interface closely and adds whiteboard visuals, yet it has notable gaps: for example, AFFiNE currently lacks full mobile support\[8\] and some features remain early in development. Also, AFFiNE (by Toeverything) uses a Business Source License (BSL) for code – meaning it’s not truly open-source in the FOSS sense, a point critics have noted\[9\]\[10\]. Our project will differentiate by being fully open-source (permissive or OSI-approved license) to encourage community trust and contributions. Functionally, we will focus more on deep AI integration than AFFiNE has so far. AFFiNE does offer an AI assistant (currently a paid add-on)\[11\], but our product is “AI-native” – features like semantic search and GPT-based helpers are core to the experience, not bolt-ons. We may not include a whiteboard at first (AFFiNE’s standout), but by concentrating on smarter document workflows, we cater to users who want intelligence in their notes rather than just another canvas tool. In sum: more AI, true open-source licensing, and a contributor-friendly culture will set us apart from AFFiNE’s approach while still embracing local-first and offline capabilities that AFFiNE champions\[12\]. Versus AppFlowy: AppFlowy positions itself as an offline Notion alternative built with Flutter and Rust. It provides a similar feel to Notion but deliberately simpler – users have noted it lacks some basic Notion features (for instance, early versions did not allow nesting pages within pages)\[13\]\[14\]. AppFlowy also requires a desktop app (no web access without using their cloud sync)\[15\]. Our product will differ by delivering a full page hierarchy and reorganization capabilities from the start, so power users can structure information freely. We’ll also support a web/browser interface along with desktop apps, giving more flexibility (self-hosted web access for those who want it, which AppFlowy doesn’t natively offer yet\[15\]). Technically, AppFlowy uses Flutter, which is great for native feel but raises the bar for contributors (they need to know Dart/Flutter). In contrast, we plan a web-stack (TypeScript + familiar frameworks) for broader dev accessibility. We also intend to avoid limitations like requiring login for certain features – e.g. AppFlowy’s Notion import only works with an online account\[16\], whereas our tool will allow data import/export offline. By learning from AppFlowy’s trade-offs, we aim to be more feature-complete in core note-taking, more accessible platform-wise, and more welcoming to extension and customization (AppFlowy’s strong suit is extensibility, which we’ll match through our plugin system and open architecture). Versus Outline: Outline is an open-source team knowledge base wiki (focused on documentation and internal guides). It’s quite mature and polished for collaborative documentation, but Outline has a different philosophy: it’s markdown-based and cloud-oriented. Users have observed that Outline, while fast and slick, can be harder to self-host (complex setup, heavy resource usage)\[17\] and it lacks a desktop or mobile app (it’s web only)\[18\]. It also doesn’t have Notion’s rich inline databases or the flexible block model – Outline pages are essentially long Markdown docs. Our product takes a more dynamic Notion-like approach (blocks, inline elements, databases) to support a wider variety of content (tasks, spreadsheets, etc.) that Outline doesn’t handle in-document. We also improve on certain UX friction points of Outline: for example, Outline requires clicking “publish” on each new page to make it visible\[19\], and it lacks a quick page creation command – our app will auto-save pages and provide quick-create via keyboard to keep flow state uninterrupted. Furthermore, Outline doesn’t have built-in AI features; we will be AI-first, offering capabilities Outline users would only get via external tools. Finally, licensing: Outline uses a BSL 1.1 license (source-available but with use restrictions)\[20\]; our project will be genuinely open and community-driven, avoiding any “open-core” pitfalls. In positioning, think of our product as Outline’s collaboration and speed meets Notion’s flexibility and AI superpowers, all in a hackable, self-hostable package. For teams that found Outline good but not powerful enough, or Notion powerful but not private enough, we aim to hit the sweet spot. Versus Logseq (and similar PKM tools): Logseq is a local-first, open-source knowledge base with graph links (a “second brain” tool). It’s fantastic for privacy and linking thoughts, but very different in paradigm – Logseq is outline/wiki-text based (akin to Obsidian or Roam), not a polished WYSIWYG database interface. Beginners find Logseq’s approach complex with a steep learning curve\[21\], and it doesn’t provide the familiar Notion-like tables, boards, or collaborative editing. Our product will appeal to those who want an easier, more visual organization (pages, tables, drag-and-drop) rather than Logseq’s markdown + backlinks approach. Also, where Logseq shines in personal knowledge graphs, it’s not as straightforward for managing tasks or structured data; our inclusion of Notion-style databases addresses that use case. We share Logseq’s strengths – working offline, privacy-first, open source – but present it in a friendlier UX that could invite a broader audience. Additionally, we’ll incorporate AI to enhance notes (imagine having Logseq’s knowledge graph plus the ability to ask questions from it in plain English – that’s what we deliver). Essentially, compared to Logseq, we sacrifice a bit of raw “Zettelkasten” philosophy in favor of intuitive design and AI assistance, aiming to be a more approachable yet still powerful knowledge base. To summarize, our new entrant differentiates itself by combining the best aspects of these tools while addressing their pain points: - Like AFFiNE and Logseq, we are local-first and privacy-centric, but we’ll provide better mobile support and truly open licensing\[8\]\[10\]. - Like AppFlowy, we’re open source and offline, but with a more complete feature set (page hierarchies, web access, etc.) and a modern web tech stack for contributors\[1\]\[15\]. - Like Outline, we target team knowledge sharing, but with richer content types, built-in AI, and easier self-hosting (lighter deployment, less friction in editing)\[19\]. - And uniquely, we double down on AI-native functionality and a viral community-oriented extension model that none of the above have fully realized yet. Positioning: Local-First, Privacy-First, & AI-Native We will position the product clearly in the market as a local-first, AI-powered knowledge base. This positioning means: - Local-First & Self-Hosted: Users can start using the app entirely locally (no account, no cloud needed) – just download and go. All features, including AI helpers, work with local data. If users want to collaborate or access data on multiple devices, they have the option to self-host a server or use p2p sync; however, this is opt-in. By not forcing the cloud, we stand apart from Notion (cloud-only) and appeal to those who value control. This approach follows the next-generation local-first architecture advocated by researchers (combining the benefits of offline apps with seamless sync when needed)\[22\]. It also allows things like end-to-end encryption for collaboration down the line, which we plan to support so that even when syncing, user content stays private\[22\]. - Privacy-First: Because data is local or on servers the user controls, privacy is inherent. We will not collect telemetry without consent; any AI features that require external APIs will be transparent and user-controlled (e.g., user provides an OpenAI API key or points to a local model). This addresses the concern many have with Notion or other SaaS tools where sensitive notes are on someone else’s server. Our open-source nature further reinforces trust – anyone can audit the code to verify nothing nefarious happens with their information. In marketing, we’ll stress that this is your knowledge, under your terms, suitable even for confidential projects. - AI-Native: Unlike tools that are retrofitting AI (such as Notion adding NotionAI later, or AFFiNE having a separate paid AI module\[11\]), our application is built with AI in mind from day one. This means the user experience naturally weaves AI suggestions and queries into workflows (we’ll detail this in the UX brief). It’s “AI-first” in the sense that features like semantic search and automated summarization are not afterthoughts or plugins – they’re core capabilities that enhance the knowledge base experience. Our positioning can highlight scenarios like “Ask your knowledge base” or “Get insights and summaries with one click” – conveying that this tool doesn’t just store information, it actively helps make sense of information. This is a compelling angle as AI is a hot differentiator, but we combine it with local privacy (which few AI-enabled apps do). In essence, we pitch the product as the best of both worlds: the empowerment and security of a local app with the intelligence and modern UX of a cloud AI service. This unique positioning will attract users frustrated by the trade-offs of current solutions (power vs. control, smarts vs. privacy). We also make it clear we’re open-source and community-driven – so early adopters know they can influence the direction and that the tool will remain sustainable and transparent. Planned Virality and Community Growth Achieving virality and strong contributor momentum is a key goal. We plan several strategies baked into the product to encourage sharing and community participation: Shareable Content Links: Users will be able to easily share pages or workspaces. For example, a user documenting an SOP or writing a knowledge article can hit “Share” and get a public link (either by publishing to a small cloud-hosted gateway or generating a sharable file). These pages can be read by others without needing the app, lowering the barrier for new people to see the product in action. Similar to how Notion allowed public page sharing which drove a lot of word-of-mouth, we’ll enable one-click publishing of read-only pages (perhaps via an optional free cloud service or by letting users host a static site export). When others view that shared page, we can include a subtle badge or call-to-action like “Made with X – try it yourself!” to drive referral traffic. Community Templates Gallery: We will foster a library of templates contributed by the community – for project plans, CRM boards, class notes, personal journals, etc. Notion’s templates played a big role in its growth, and we want a similar effect. Within our app, users can import a template from the gallery in a couple clicks (e.g. “New from Template” – picking from popular templates). Conversely, users can export their pages as templates and submit to the gallery. This creates a virtuous loop: as more templates (especially ones showcasing AI usage or novel workflows) appear, more users find immediate value; some will contribute back their own. Templates will also make it easier for novices to get started, improving adoption. Plugin Ecosystem and SDK: We’ll launch with a plugin system that invites developers to build add-ons. By making the platform extensible from day one, we harness the creativity of the open-source community. We’ll provide a clear plugin API (for adding UI elements, custom block types, integrations, etc.) and documentation. Even if only a few plugins appear early, we will highlight them to show momentum. For example, a developer might create a plugin to integrate a third-party task tracker, or a plugin to add a new visualization for database data. We plan to list community plugins on our website or a GitHub repo, and possibly an in-app plugin browser later. This not only adds functionality rapidly (through crowd-sourcing development) but also drives adoption – if someone builds a popular plugin, their user base will need our base app to use it. Being open-source and modular here is a huge advantage over Notion (closed platform) and will attract contributors who want to shape the tool to their needs. Community Forums & Showcase: We’ll actively run a community (likely on Discord or a forum) where users can share how they use the app, ask questions, and showcase cool setups. Encouraging users to show off their workspaces or hacks can inspire others. We might periodically feature “community highlight” templates or publish blog posts about interesting use cases (with user permission). By making early users feel like members of a movement rather than just consumers, we deepen engagement. This helps turn users into ambassadors who advocate for the tool in their circles (as often happened with Notion and Roam’s cult followings). Collaboration Invites: As team features mature, we’ll incorporate viral loops in collaboration. For instance, a user can invite colleagues to collaborate on a workspace via email invite – those invitees get easy instructions to join (either by downloading the app or visiting the self-hosted web portal). Teams grow virally as one person brings in others. Even without a centralized cloud, this can be achieved with self-hosted instances or peer-to-peer – the key is smooth UX for invitation (perhaps generating a link or code that others use to connect). This way, one enthusiastic user in a company can spread it to dozens. Open Development Model: On the contributor side, we’ll operate in the open – publishing a public roadmap, tagging issues good for first-time contributors, and being responsive on GitHub. This transparency and welcome attitude will attract developers who are looking to contribute to a meaningful project. We’ll also credit contributors prominently (e.g. a CONTRIBUTORS file, shout-outs in release notes) to encourage pride and word-of-mouth. When developers feel ownership, they naturally promote the project in their networks. Integration with Social Coding Platforms: We might integrate with GitHub/GitLab for certain flows (for example, backing up content or publishing to a Git repo for version control). While not exactly “viral,” this appeals to developer-users and can indirectly market the tool in those communities. Imagine a user pushes their knowledge base to a public GitHub repo – others might discover it and thus discover our app. Through these measures, we aim to achieve a compound growth: the product spreads both through user-sharing (templates, published pages, invitations) and developer engagement (plugins, contributions). Many modern OSS products have grown via community-driven virality, and we intend to do the same, making sharing and extending the product a delightful experience. The result will be an ever-improving application with a passionate user base that feels invested in its success. Developer Brief Tech Stack: Language & Framework Recommendations We recommend a modern, cross-platform stack that balances performance, familiarity, and long-term maintainability. Key choices include: - Front-End: SvelteKit (TypeScript) for the client UI, paired with Tailwind CSS or a similar utility framework for styling. SvelteKit offers a highly reactive UI with less boilerplate than React, resulting in snappy performance and a minimalistic codebase (aligning with our speed and minimalism goals). It can produce a bundled web app that we can deploy in multiple environments (desktop via Tauri, web via a Node server or static build). Using TypeScript ensures type safety and clarity for contributors. Many web developers can pick up Svelte quickly, and it yields very small, efficient bundles – crucial for a desktop app with lots of dynamic interactions. Alternative: If not Svelte, React+Vite could work since React has a large talent pool, but we lean Svelte for its simplicity and smaller footprint. - Desktop Wrapper: Tauri (with Rust) to package the app as a desktop application. Tauri has significant advantages over Electron: extremely small bundle size (Tauri apps can be ~10MB vs hundreds for Electron) and lower memory usage by leveraging the OS’s WebView\[23\]\[24\]. Tauri’s Rust core also gives us system-level access and performance for heavy tasks. Since we are building a local-first app, being lean and efficient is important – Tauri will allow even older machines to run the app smoothly, and users will appreciate the quick launch and low resource usage. (Benchmarks have shown Tauri apps using less than half the RAM of equivalent Electron apps\[24\].) Using Tauri means our front-end is essentially a web app (Svelte) running in a secure webview, with Rust available for backend logic. - Backend/Core: We propose writing core logic in Rust, compiled to WebAssembly for use in the front-end and natively for the Tauri backend. This gives a unified, high-performance core that can be used in multiple deployment modes. For example, our sync engine or database logic could be in Rust – in a browser context it runs as WASM (ensuring fast performance in a web-only deployment), and on desktop it can run natively via Tauri’s Rust side or the same WASM. Rust is memory-safe and excellent for data-intensive tasks (like text indexing, encryption, etc.). By using Rust, we also tap into its strong library ecosystem for things like CRDTs, databases, and AI (there are Rust crates for embedding models, tokenization, etc.). While this adds a second language for contributors to know, many open-source devs appreciate Rust, and isolating heavy logic in Rust means the majority of UI work can still be done in TypeScript. This hybrid approach (TypeScript for UI, Rust for core) gives us the best of both worlds – ease of contribution and cutting-edge performance. - Web Server (Optional Self-Hosted Mode): If providing a server edition, we can reuse the Rust core and build a small API server (using a framework like Axum or Actix in Rust, or even Node.js/Next.js if sticking to TS). However, to keep one codebase, a Rust web server that shares logic with the Tauri app is ideal. Rust can compile to a single binary that includes an embedded database and our application logic – making deployment via Docker trivial. For example, we might compile a CLI that runs a local HTTP server serving the Svelte app and handling synchronization. This dual approach (desktop and server) ensures organizations can self-host for multi-user access, while individuals can stick to the offline app – both using largely the same code. - Database/Storage: For local storage, using an embedded database like SQLite (possibly via the excellent sql.js for WASM, or via a native binding in Tauri) is recommended. SQLite is file-based and works offline, and we can encrypt the database file for security. It’s also server-capable (a server deployment can use a more robust DB like PostgreSQL if needed, but SQLite could even handle small-team web use). Another angle is to use a CRDT-based storage (Conflict-free replicated data types) such as Yjs or Automerge. Yjs (JavaScript/TypeScript library, with a Rust port yrs) is specifically geared for real-time collaborative data structures\[25\]. We could combine the two: for structured data and large text, SQLite, and for real-time collaborative in-memory doc model, Yjs that flushes to SQLite. Yjs would allow peer-to-peer sync and offline edits merge, aligning with local-first principles that AFFiNE and others use (AFFiNE chose CRDT for decentralization and conflict resolution in offline edits\[22\]). In any case, the architecture should abstract the storage layer so that it can switch between a file or server DB seamlessly. - AI Integration: For AI features, our stack will involve some AI service or library. Likely we start by integrating with external APIs (OpenAI, etc.) through network calls, which can be done from the Rust side or directly in TS. Eventually, we might include an on-premise AI option (like running a local Transformer model) using something like llama.cpp or other Rust ML libraries. The dev stack needs to be flexible here – using Rust for AI integration could be wise (better performance for heavy tasks like embedding generation), but Python is a contender if we needed advanced NLP (though bundling Python is heavy). Given our constraints, we’d likely use Rust or Node libraries for AI (e.g. tiktoken for tokenization in Rust, calling OpenAI’s REST API for generation initially, etc.). We will design a simple AI service interface so that the implementation can swap (cloud vs local model) without changing the app’s UI. In summary, we favor Tauri + SvelteKit + Rust (WASM) as the primary tech stack. This choice is justified by: - Performance: Rust and Tauri make the app lightweight and fast, avoiding Electron’s bloat\[23\]. - Developer Appeal: TypeScript + Svelte is approachable for many web developers (low entry barrier to contribute UI/UX improvements). Rust, while advanced, will be used in contained modules with clear APIs, and it attracts systems-level contributors. This combo aligns with “cool, modern stack” which itself can attract interest on GitHub. - Consistency & Flexibility: We can target desktop and web from one codebase. Also, using WebAssembly means even in the browser the heavy logic runs at near-native speed, crucial for things like full-text search or cryptography. - Safety and Robustness: Rust’s safety helps prevent crashes and memory leaks, which is important for a long-running app handling potentially large in-memory docs or AI processing. The developer community increasingly embraces such multi-language setups (for instance, AppFlowy uses Flutter+Rust, and many web apps use WASM modules for critical paths). We believe this stack will keep our app future-proof, efficient, and contributor-friendly. Architecture & Module Layout We will structure the project in a modular architecture to isolate concerns and make it easier for new contributors to understand. A high-level breakdown of modules/components: Editor Engine Module: This is the core of the content editing experience. It will handle the document model (blocks, their content and hierarchy), editing operations (insert, delete, move blocks), and rendering of the editor UI. We will likely base this on an existing rich-text framework for reliability – for example, using ProseMirror with the Tiptap wrapper as our editor engine. Tiptap provides a block-based editor API that is customizable and already supports collaboration via Yjs. This module would include our custom block types (text, headings, todos, etc.) and define how they’re rendered in Svelte components. It might also include the slash command menu logic. By encapsulating the editor, we ensure that the rest of the app can treat it as a black box (with an API to get/set document content, or listen to changes). Data & Sync Layer: This module handles data persistence and synchronization. It will encompass: The Local Database (likely a wrapper around SQLite or file storage, including an encryption layer if needed). The CRDT Sync Engine (if using Yjs, this is where we set up Yjs docs and providers). For example, each page could be a Yjs document allowing real-time collaboration. Yjs can sync via multiple providers – we can write a provider that syncs to our server or to a file. AFFiNE’s team open-sourced BlockSuite/OctoBase, a Rust-based CRDT datastore; we might not use it directly, but we draw inspiration to have a clear boundary between in-memory collaborative state and stored state. The sync layer will also manage conflict resolution and merging, leveraging CRDT’s properties to automatically resolve concurrent edits\[26\]\[27\]. The Server Communication sub-module: if connected to a self-hosted server or peer, this part uses WebSockets or similar to exchange updates. If no server (solo mode), it’s dormant. Possibly a File System interface for exporting/importing (like import from Notion Markdown/CSV, export to Markdown or PDF). AI Services Module: A distinct module for AI-related functions. This includes: Semantic Search Index: We might maintain an index of vectors (embeddings) for each note to enable semantic search. This module would use an embedding model (via API or local) to generate embeddings when notes change, and store them (possibly in a small vector database or even just a local file). It provides a search function that given a query, returns relevant notes (maybe using cosine similarity). Natural Language Processing: Functions for summarization, question-answering, text generation. Likely these call out to an AI API initially. We’ll abstract this behind an interface (e.g., AI.generateSummary(text): string) so that the actual implementation can switch between OpenAI, Anthropic, or local models. This module can also enforce usage limits or batching as needed. We keep AI logic separate so that contributors focused on AI can work here without touching core editor code, and vice versa. Plugin/Extension Module: From the start, we will design the app to be extensible. Internally, this means having a plugin loader that can register new features. The plugin system might allow plugins to: Add new block types or editor features (e.g., a plugin could introduce a mind-map block or a calendar view block). Add commands (for example, a plugin could add a “Translate text” option in the AI menu). Integrate with external services (a plugin could sync content to GitHub, etc.). Possibly have their own UI panels or settings. To facilitate this, our architecture could use an event bus or dispatch system where different modules communicate via events. AppFlowy’s architecture describes an event-dispatch mechanism to decouple modules\[28\]. We can implement something similar: core modules emit events (like “page opened”, “text selected”) which plugins can listen for and react to. Conversely, plugins can trigger actions via defined extension points. This separation means the core can remain lean, and almost any feature could potentially be a plugin, keeping the core uncluttered. Front-End UI Module: This refers to the SvelteKit front-end that ties everything together. Within the UI, we might further separate: Navigation/Workspace UI (sidebar, page tree, breadcrumbs, search bar, etc.), Page Content UI (which is essentially the editor module’s UI), Modals/Popovers UI (for things like the slash command menu, sharing dialog, template picker, etc.), Settings UI (preferences panel including theme toggle, keybind settings, etc.). The UI will call into the other modules via well-defined interfaces. For instance, when the user hits “Save” or when auto-save triggers, the UI calls the Data module to persist, which in turn might send CRDT updates to peers. When a user triggers an AI action, the UI calls the AI module and then displays the result. Server (optional) Module: If running in server mode, a lightweight web server that serves the compiled front-end and provides API endpoints for multi-user sync and auth. We can design it so that this server reuses the Data & Sync Layer code – essentially running headless without the UI. This module would handle user accounts, authentication (maybe JWT or OAuth for organization use), and room management for collaborative editing sessions. For a small team self-host, a built-in basic auth or OAuth integration (like Outline supports Google OAuth) could be included. The architecture draws on Domain-Driven Design principles to keep boundaries clear. For example, we separate the domain logic (like how a page is structured, how blocks relate, what constitutes a valid operation) from infrastructure (like how data is stored or transmitted)\[29\]\[30\]. This ensures we could swap, say, the storage layer from SQLite to another DB without touching how the editor works. It also makes testing easier — e.g., we can unit test the domain logic of merging two text blocks without needing a real database. From a repository standpoint, we likely will use a monorepo with perhaps multiple packages: - web-app (Svelte front-end), - core (Rust crates for core logic, possibly split further into core-editor, core-sync, core-ai crates), - server (if separate), - plugins (maybe a directory of example plugins or plugin SDK code). We’ll include an Architecture.md document (much like Outline’s architecture overview\[31\]) to explain this structure to new contributors. By cleanly delineating modules, a developer can work on one area (say, improving the search ranking algorithm in AI module, or fixing a list rendering bug in the editor module) without deep knowledge of the entire system. This modular design also means new features often can be added as a plugin or in a contained way, preventing regression in unrelated areas. Contributor-Friendly Design (Docs, Modularity, Onboarding) We want to cultivate an active open-source contributor community from day 1. To do that, we will: - Comprehensive Documentation: We will provide thorough developer docs and comments. This starts with a detailed README and CONTRIBUTING.md that explains how to set up the dev environment, the project structure, and coding guidelines. We’ll also document the architecture as mentioned, plus have docs for the plugin API (so plugin developers can easily get started). Inspired by Outline, which has guides for setting up a development environment and even an architecture doc\[32\]\[31\], we’ll ensure our docs lower the barrier to entry. Additionally, we’ll maintain up-to-date API reference (perhaps using TypeDoc for TS and cargo doc for Rust, and publishing those). - Modular, Readable Code: By splitting logic into clear modules, a contributor can focus on one portion without being overwhelmed. Each module will have a clear responsibility and minimal coupling. We’ll enforce code style and linting (ESLint for TS, rustfmt/clippy for Rust) to keep the codebase consistent, which makes it easier to read and contribute to. We’ll also try to follow clean coding practices and patterns familiar to many (for example, using MVC/MVVM patterns in the front-end, or Redux-like state management if suitable, etc., so that structure feels familiar). - Dev Environment and Tooling: We aim for a one-command setup. For example, using a package manager script or Docker compose to spin up any needed services. If using Tauri, we’ll document the prerequisites (Rust toolchain, etc.). We might provide a dev container config or a script that sets up the database and runs migrations. Fast iterative development is key: changes in Svelte should hot-reload in the app; we’ll configure that if possible with Tauri (Tauri dev mode can reload the webview on file changes). The easier and quicker it is to see your changes, the more welcoming it is for new devs. Additionally, we’ll integrate continuous integration (CI) early for running tests and linters on pull requests, giving contributors quick feedback (and confidence that their PR didn’t break anything). - Issue Tagging and Mentorship: We will tag beginner-friendly issues (good first issue) and write clear problem statements for them. This helps newcomers find a way to contribute meaningfully. The core team (or founder) will be active in code reviews, offering supportive feedback and guidance to new contributors. We can also set up a Discord/Slack where devs can ask questions and get help setting up. An inviting community vibe is as important as the code structure in retaining contributors. - Extensibility from the Start: As mentioned, the plugin system means contributors don’t even have to upstream their ideas – they can create a plugin independently. This lowers friction: someone can tinker with a new feature as a plugin without needing approval, and if it’s great, we can later merge it or feature it. We’ll encourage this by providing a plugin example template and maybe running periodic “plugin hackathons”. In short, we treat contributors not just as bug-fixers but as creators who can expand the ecosystem. - High-Level Roadmap & Priorities: We will publish a public roadmap (perhaps as GitHub issues/milestones or a markdown file) so contributors know what big things are planned or needed. This avoids duplicate work and invites community input on direction. It also signals that the project is active and forward-looking (important for motivating volunteers). - Testing and Quality: While it may not be glamorous, we’ll set up a testing framework (Jest or Vitest for TS, and Rust’s built-in test framework for core logic). We’ll encourage adding tests with contributions, especially for core logic. Having tests gives contributors more confidence to modify code without fear of breaking everything. We won’t mandate 100% coverage, but critical pieces (like data sync, permission logic, etc.) should be well-tested. - Code of Conduct and Recognition: We’ll adopt a contributor Code of Conduct to ensure a welcoming, inclusive environment. And we will recognize contributors – for example, adding their names in release notes or a contributors page, perhaps giving out swag or badges for significant contributions. Feeling appreciated goes a long way in OSS communities. In essence, we want to replicate what successful OSS projects do: clear docs, a logical codebase, and an approachable, helpful community. By reducing the cognitive load to understand the project and providing quick payoff (like “I made a change and it reflected in the app immediately!”), we make contributing rewarding. This is especially important because we’re combining languages (TS and Rust); we’ll ensure that boundaries are well-defined (with comments explaining, for instance, how the TS UI calls into a WASM function, etc.) so devs don’t get lost in interop details. We can also provide scripts for common tasks (like npm run dev:ui and npm run dev:server, npm run build:wasm etc.) to abstract build steps. Ultimately, our aim is that a developer discovering our project can get it running in minutes, understand the major pieces in an hour, and open their first PR in a day or two. If we achieve that, we’ll rapidly build a strong contributor base to help drive the project forward. Key Libraries & Tools To avoid reinventing the wheel and to leverage community best practices, we will use several proven libraries and tools in our implementation: Block-Based Editor Library: We plan to use Tiptap (ProseMirror) for the rich-text editor. Tiptap is an open-source toolkit that wraps ProseMirror, providing a high-level API for building Notion-style editors with extensions. It supports collaborative editing with Yjs out of the box and is framework-agnostic (can integrate with Svelte via its headless core). Using Tiptap means we get a lot of functionality (history, copy-paste, complex text styling, etc.) without building from scratch, and we can define custom node types for any specialized blocks. This saves us from the very heavy lift of writing our own editor engine, which AppFlowy had to do for Flutter. ProseMirror is battle-tested and used in many editors (like Atlassian’s), so it handles edge cases of contenteditable, making our editor more robust from the start. If not Tiptap, another option is Slate.js or Lexical (Meta’s editor framework), but those are more React-centric or less proven with collaborative editing. Tiptap’s extension system will let us add things like slash commands easily and even allow 3rd-party extensions (plugins) to augment the editor. CRDT & Real-Time Sync: Yjs will be our go-to for CRDT implementation. Yjs provides shared data types suitable for text and other structured data, letting multiple clients merge changes seamlessly\[25\]. We’ll likely use Yjs for representing the document state in the editor, enabling real-time collaboration without central conflict resolution. Yjs also has persistence adapters (like y-indexeddb for offline storage) and network adapters (y-websocket, y-webrtc) we can leverage. For instance, in local mode we use y-indexeddb to save changes, and in multi-user mode, we use y-websocket to sync via our server or a signaling server. The decision to use CRDT/Yjs is guided by successes in similar projects – AFFiNE explicitly chose CRDT over OT for easier decentralization and conflict handling\[27\]. By using Yjs, we tap into an ecosystem of tools and even potential integrations (for example, TipTap’s collaboration kit uses Yjs, and there are Yjs bindings for ProseMirror already). Database/Storage: For structured data and as a backup store, we’ll use SQLite. On desktop, we can embed SQLite via Tauri’s plugin or a pure Rust crate (like rusqlite). On web, if needed, we can use sql.js (SQLite compiled to WASM) to work with the same database file format. SQLite gives us a simple way to query and organize data (for example, it can store our user settings, a table of pages for quick lookup, the search index, etc.). For multi-user web deployments, we can swap SQLite with PostgreSQL or another server DB by using an ORM or abstraction (maybe Diesel or Prisma). However, to start, focusing on SQLite keeps things simple. We can implement a repository pattern so that switching DB is possible without changing business logic. Search and Indexing: We will incorporate a search library for full-text indexing. One option is Lunr.js or FlexSearch for client-side full-text search on web (for smaller data sets). However, since we plan semantic search, we might not need a traditional inverted index for plain text. Instead, we’ll build a vector index. Possibly use a library like Vald (if heavy) or simpler, just store embedding vectors in a binary file or SQLite blob and do a brute-force cosine similarity (which is fine if data is not too huge). If performance becomes an issue, there are Rust libraries for ANN (approximate nearest neighbor) search we could incorporate (like faiss via FFI or pure Rust like hnswlib). This area might evolve; initially, a straightforward approach of computing embeddings and scanning should suffice for MVP with small-medium note collections. AI API Integration: For connecting to AI models, we might use existing SDKs. E.g., OpenAI has Node and Python libraries, but in Rust we might call their REST endpoints directly using reqwest (Rust HTTP client). If we decide to bundle a small model, we might use Hugging Face’s tokenizers library (there’s a Rust version) for text processing and something like onnxruntime or ggml for running a local model. However, these choices will depend on feasibility on user machines (running even a 7B model locally has high RAM usage). Likely, we’ll abstract this so that by default it calls cloud APIs (which we document, so privacy-conscious users know when data would go out and can disable if needed). UI Components: To build the UI quickly and accessibly, we might use component libraries or kits. For example, Radix UI (unstyled accessible components) has a Svelte port for things like dropdowns, modals, etc., ensuring we get proper keyboard navigation and screenreader support. We can also use headless UI components to implement our menus and comboboxes (like the slash command menu, which is essentially a filterable list – there are patterns/libraries for that). We’ll use Heroicons or similar for icons (to have a nice icon set for buttons). State Management: Svelte has built-in stores which might suffice for global state. We might not need something like Redux given Svelte’s reactivity, but if the app grows complex, we could consider a state management library for consistency. For now, likely Svelte’s context and stores will do (for example, a store for current user, a store for offline/online status, etc.). Markdown Parsing and Export: We should include a Markdown library (like remark or marked) to handle imports/exports. Since many users will want to import from or export to Markdown (Logseq/Obsidian folks, for example), having a robust parser and renderer is important. We can use unified + remark-parse for parsing Markdown into a syntax tree, and then map that to our internal format. For export, we can invert the process. Similarly for other formats (HTML export for publishing). Testing Tools: Jest or Vitest for JS tests, and standard Rust test harness for Rust code. If we test the UI, we can use something like Playwright or Cypress for end-to-end tests (e.g., spin up the app in headless mode and simulate user actions). For accessibility tests, we might include something like axe-core in tests to catch issues. Continuous Integration: GitHub Actions for running tests on push/PR, and maybe building release binaries for each platform when we tag a release. Tauri has GitHub Action templates to build installers for Windows/macOS/Linux, which we’ll utilize to streamline releases for users. By leveraging these libraries and tools, we avoid solving already-solved problems and adhere to best practices. For example, using Yjs for collab is becoming a de facto standard – it’s better than writing a custom OT/CRDT from scratch. Similarly, Tiptap gives us a cutting-edge editor (that supports extensions like mentions, tables, etc.) so we concentrate on product-specific bits. These choices also help with contributor familiarity: many developers may have used these libraries elsewhere and can jump in. If someone has built a ProseMirror plugin or worked with Yjs in another project, they can apply that knowledge here. Importantly, using open libraries aligns with our open ethos – our stack is transparent and avoids proprietary traps. Each chosen component is well-regarded in the open-source community, which means longevity and community support. We will of course keep an eye on license compatibility (everything listed is MIT/Apache or similar, which is fine for an MIT/AGPL project we’d likely be). In summary, the stack will include: - Frameworks: SvelteKit, Tauri (Rust) - Editor: Tiptap/ProseMirror (with Yjs for collab) - Data Sync: Yjs CRDT + SQLite for persistence - AI: OpenAI API (initially) and possibly local model support (Rust ML libs) - UI/UX: Tailwind CSS, Radix UI, Heroicons, etc. - Build/Test/CI: Vite, Vitest, GitHub Actions, etc. This combination ensures we build on the shoulders of giants, speeding up development and aligning with emerging best practices in the OSS productivity tool space. Hosting Model & Deployment Path One of our strengths is flexibility in how the software can be run. We plan to support multiple deployment models to cater to different user preferences: Local-Only (Desktop App): The primary distribution will be a desktop application (Windows .exe, Mac .dmg, Linux AppImage/Deb). This is powered by Tauri, as discussed, and means the user can download the app and run it with zero setup. All data by default is stored locally (e.g., in the user’s AppData or Documents folder, or a custom path the user configures). Even AI features can work here, though if they rely on cloud APIs the user would need internet (we’ll allow them to disable AI if fully offline). The desktop app will periodically update (we can implement an auto-updater, Tauri provides one, or users can get notified of new versions). For many individuals, this will be the easiest and preferred way, since it’s similar to Obsidian or Notion’s Electron app – except in our case it truly works offline and doesn’t phone home. Self-Hosted Server (Web App): For teams or users who want to access their notes from multiple devices through a browser, we’ll offer a Docker image or installation script to run the app on a server. This server will essentially run our Rust backend and serve the Svelte front-end over HTTP. Users can then connect via web browser, create accounts, and collaborate in real-time. All data resides on the server’s disk or database, under the user’s control (if they run it on their own hardware or cloud). We will provide a Docker Compose file that sets up the web service and a database service (if using Postgres in this mode, for example) so that running the stack is as easy as docker compose up. Documentation will guide through configuration (like setting an admin user, enabling HTTPS via proxy, etc.). This model makes our app comparable to tools like Outline and Mattermost’s Focalboard – one can host an instance for their team or community. Hybrid & Sync: Some users might want a bit of both: use the desktop app offline, but also sync data across devices or with teammates. Our architecture (with CRDT) envisions a hybrid sync model. We could provide an optional “personal cloud” component – perhaps the same server as above, but for personal use. For instance, a user could run a lightweight headless server on a Raspberry Pi or a VPS and point their desktop app to it for sync. Alternatively, we implement p2p sync: if two devices are online, they find each other (maybe via a simple relay server) and sync directly. Anytype.io does something similar with a generated key for p2p sync\[33\]\[34\]. Initially, we might rely on the simpler approach: a cloud relay (which could be our provided service or self-hosted). We will certainly ensure that even if using a cloud relay, all data is end-to-end encrypted (so the relay can’t read it), thereby maintaining privacy. Mobile Access: In terms of deployment, mobile is tricky. We are deferring native mobile apps, but we will ensure the web app is responsive so mobile browsers can at least view content (editing might be limited due to complex editor interactions on touch). If there’s demand, in the future we could wrap the web app in a tool like Capacitor to deploy as a mobile app, or use Tauri’s coming mobile support. The key for now is that the self-hosted web can be reachable from a phone for quick reference. Some advanced users might even run the app in Termux on Android (given it’s just a web server and some HTML) – not a primary goal, but theoretically possible for the adventurous. Deployment Path for Releases: For desktop, we will have CI build installers for each platform. We’ll likely host these on GitHub Releases (making it easy for users to download, and for package managers like Homebrew, Scoop, Chocolatey to pick up). For server, we’ll publish a Docker image to Docker Hub and maybe a binary to GitHub. We’ll version releases (0.1, 0.2, etc.) and provide changelogs. It’s important to make installation and updates simple to not turn off less technical users. So documentation will include “how to install” for both modes and troubleshooting tips (e.g., if the app can’t write to disk, etc.). Scaling Considerations: While our initial target is small teams and individuals, self-hosted instances should be able to scale to dozens or maybe hundreds of users if run on a decent server. We’ll recommend using Postgres for larger installations and possibly provide config for horizontal scaling (like running multiple app instances connected to one DB, though real-time collab via CRDT might need a single coordination server or a pubsub mechanism). We’ll test with, say, 10 concurrent editors in one page to ensure our CRDT approach holds up. For extremely large deployments (hundreds+), we might not optimize MVP for that, but being open-source, those users could adapt it or contribute improvements. Security and Updates: The hosting model will emphasize security best practices. For example, our server will support HTTPS, and perhaps provide an example NGINX config. We’ll encourage running behind a firewall or reverse proxy. Data encryption at rest can be offered (maybe optional, e.g., SQLite file encryption and using HTTPS/TLS for data in transit). When deploying new versions, we’ll detail how to backup data and migrate (if needed). Using standard tools (Docker, etc.) helps here. In summary, the deployment strategy is to meet users where they are: - If you’re an individual note-taker – use the desktop app, it’s simple. - If you’re a team – deploy the server in your cloud or on-prem and access via web (or still use desktop pointed at it). - If you want both – we’ll support syncing your local app with your self-hosted server or between devices. This flexibility is a competitive advantage. It means, for example, a user can start with the free desktop app personally, fall in love, and later convince their company to deploy it for the team. Or a team can begin self-hosted and people can also have offline replicas on laptops when traveling. We are essentially combining the offline capabilities of tools like Obsidian/Logseq with the collaborative server approach of Notion/Confluence – a tough technical challenge, but thanks to CRDT and modular design, achievable. Technically, enabling all this means careful design of the sync mechanism. We’ll likely ship the initial version with either real-time sync or at least manual import/export, and then iterate on live sync. But the architecture laid out assumes eventually we have robust sync. To avoid confusion, we’ll clearly document what’s possible in each mode. For instance: “In local mode, you have full functionality except multi-user real-time editing. In server mode, you get real-time collaboration. You can switch a workspace between local and server by exporting/importing or connecting to a server endpoint, etc.” Ensuring that user data can migrate between these modes (without lock-in) will be part of our philosophy (like how Notion lets you export everything; we’ll do the same so users never feel stuck). Overall, our hosting model strategy is to provide maximum autonomy: use the product on your terms, whether fully offline, in your own cloud, or a mix. This not only appeals to privacy-conscious users but also acts as a USP against cloud-only competitors. It is also aligned with open-source values – you can run this app anywhere, like any other open-source tool, and that itself can drive adoption in communities that avoid SaaS. UX/UI Brief Design Philosophy: Minimalism, Accessibility, Delight, Speed Our design philosophy is guided by a few core principles: - Minimalism: The interface should be clean and uncluttered, putting content first. We take inspiration from Notion’s sparse aesthetic – a simple sidebar and a content canvas – so users aren’t overwhelmed by toolbars or widgets. Every UI element should serve a purpose; if in doubt, leave it out. By keeping the chrome minimal, we also reduce cognitive load for users, allowing them to focus on their notes and ideas. This means using a lot of white space (or dark space in dark mode), subtle icons, and only showing advanced options when needed (e.g., using context menus or hover toolbars instead of permanent buttons). A minimalist approach also aids new users – it feels approachable. We will, however, include progressive disclosure: basic functionality is obvious, while more advanced features or AI suggestions might appear contextually or on user request (so they don’t complicate the UI for those who don’t need them). - Speed: We strive to make every interaction feel instantaneous. This involves both technical performance (our local-first approach avoids network lag) and perceived performance (designing interactions to have immediate feedback). The UI should respond to typing, clicking, dragging without delay – which our tech stack (Svelte + local data) will support. We will avoid heavy modal flows for common tasks; whenever possible, editing happens in place. For example, creating a new page or editing a title is done inline, not in a separate dialog that would interrupt flow. We also plan to implement keyboard shortcuts for virtually all actions (Notion users expect this), which is part of a speedy UX. A quick-switcher (Ctrl+K or similar) will let users jump to any page or command swiftly, which advanced users love. Overall, “no waiting, no friction” is a mantra – if an operation can’t be near-instant (like a large AI operation), we’ll communicate progress clearly rather than leaving the user guessing. - Delightful & Human: While minimalist, the UI shouldn’t be dull. We’ll add small delightful touches – micro-interactions like a subtle animation when you complete a task checkbox (maybe a little checkmark flourish), drag-and-drop animations when moving blocks, or a friendly illustration on an empty state. These add personality to the app. We want users to enjoy using it, not just tolerate it. The tone of any copy or prompts will be friendly and encouraging. Since we have AI, even the AI assistant’s presence can be playful (perhaps an optional cute bot avatar or something, without being distracting). We can also celebrate user milestones (for instance, if a user creates their 100th note, a tiny confetti animation could play). These little delights create emotional connection and set our UX apart. - Accessibility: From the get-go, we will bake in accessibility. This means proper semantic HTML for text (headings are actual

…
=

###### in output, lists are

, etc.), and using ARIA roles for custom components. Keyboard navigation will be a first-class citizen: users can tab through buttons, use arrow keys in menus, use shortcuts to trigger commands. We’ll ensure contrast in our theme is sufficient (meeting WCAG AA guidelines at least), especially for text and key UI elements. We will provide a way to navigate the app without a mouse – e.g., a user can open the sidebar with a hotkey, jump between blocks with arrow keys, etc. When designing any custom UI element (like a block drag handle or an AI suggestion popover), we will consider how a screen reader would announce it or how a keyboard user would interact. It’s easier to build this in early than to retrofit. An accessible app not only serves those with disabilities but often results in efficiency gains for all users (keyboard shortcuts are a prime example). - Consistency & Familiarity: We’ll use familiar patterns from Notion and traditional document editors so users feel at home. The learning curve should be minimal if someone comes from Notion or even Google Docs. For instance, the slash command menu, the way you can @-mention a page or tag, the presence of a sidebar with pages – these paradigms will be present. However, we’ll also smooth any rough edges noted in those tools. For example, Notion’s breadcrumb navigation is useful; we’ll include a breadcrumb bar at the top for nested pages so users always know where they are. Another example: Outline has both edit and read modes, which some find confusing\[19\]; we will opt for one mode (like Notion, editing is always on by default, since our permissions and share model can handle view vs edit without separate modes). This consistency extends internally too – buttons will look and behave similarly throughout, icons will be reused appropriately, etc., so the app feels coherent. - Flexibility & Customization: While minimalist by default, the UI should allow some customization to suit different workflows. For example, a user might toggle on a right-hand sidebar for extra info (perhaps an outline of the page content, or the AI assistant panel). Advanced users might want to enable a “focus mode” that hides even the sidebar for a distraction-free view, or alternatively a “split view” to see two notes side by side (we can explore this as an option later). We’ll also consider multiple themes (beyond just light/dark, maybe a few accent color choices or a high-contrast mode). Customization adds to user delight because they can make the workspace their own. It also ties into contributor guidelines – we’ll encourage contributions of themes or CSS tweaks. Overall, our UX philosophy aims to make a powerful app feel simple and friendly. We consider the pain points of current tools: Notion can feel slow or heavy at times (we fix that with local speed), Logseq can feel intimidating (we fix with friendly UI), Outline can feel limited in formatting (we fix with richer Notion-like blocks), etc. By adhering to these principles, we ensure that adding lots of functionality (AI, databases, etc.) doesn’t turn the UI into a confusing mess. We keep it straightforward and user-centric at every step. Major UX Flows We have several key user flows that define how someone will use the application on a day-to-day basis. We aim to make these flows intuitive and efficient: Creating a New Note/Page: The user can create a new page from multiple entry points: a “+ New Page” button in the sidebar, a keyboard shortcut (e.g. Ctrl+N), or via the slash command (typing “/page” within another page to create a sub-page). Upon creation, a new page appears in the content area with a placeholder for the title (e.g., “Untitled”). The user simply starts typing the title, then presses enter to begin writing content. The new page is automatically added to the sidebar (perhaps under a selected workspace or parent page). We ensure no friction like additional dialogs – it’s instantaneous. If created via slash command inside another page, we treat it as a sub-page (for example, the text the user typed might become an inline link to the new page which opens when clicked). Auto-saving is in place, so the user never worries about a save button – the note is persisted as they type. This flow addresses a core scenario: quick capture of a new idea or document. It should feel as seamless as jotting something on a sticky note. For organization, after creation, the user can drag the page in the sidebar to reorder or nest it, reinforcing the intuitive page management (lack of such ability was a complaint with AppFlowy’s early version\[1\], which we explicitly solve). Creating a New Database (Table/Kanban): If the user wants a structured dataset (like a task board or list of contacts), they should be able to create that easily. One flow is via a template or option: when clicking “+ New Page”, we can offer choices such as “Blank page” vs “Table” vs “Kanban board”. If they choose “Table”, we create a new page that is pre-set as a database type – meaning the content area is a table layout rather than freeform text. The user can then add columns (properties) like in Notion (text, number, select tags, etc.) and add rows (records). Similarly for Kanban, a board view with columns appears. We will make these flows similar to Notion’s for familiarity – e.g., the user could alternatively type “/table” in a page to insert an inline table or convert a page into a database. The key UX point is to guide the user initially: perhaps when the new DB page opens, we show a small hint panel “Add columns to define your database structure, double-click to edit cells”, etc., to reduce confusion. The design of the table/board will be minimalist but clear – resembling Notion’s styling (grid lines, headers). By including a native flow for structured content, we differentiate from apps like Logseq and Outline which don’t do this at all, and match Notion’s power. Over time, we’d expand capabilities, but initial flows cover basic adding/removing columns and switching views (list, board). This also ties into templates – e.g., user could pick “Project Tasks Board” template which is a pre-configured Kanban with sample columns like “To Do/In Progress/Done”. Taking Notes & Editing Content: The bread-and-butter flow is writing and editing on a page. The UX here should be on par with best-in-class editors. The user clicks anywhere and types to create a text block. Hitting enter creates a new block (paragraph). They can format text using either markdown shortcuts (typing “# ” turns into heading, or “- ” starts a bullet list) or toolbar actions. We’ll provide a contextual toolbar that appears when you highlight text (for basic formatting like bold, italics, link – similar to Notion’s hover toolbar). Also a persistent “+” button on empty lines or at the left side of a block to quickly add something (this triggers the block picker, same as slash command). Dragging: we’ll have a handle on each block (e.g., a ⋮⋮ icon) that you can drag to reorder the block up/down or into another page (drag to sidebar). Multi-select of blocks (via shift-click or drag selection box) should be supported for bulk operations (moving, deleting). These interactions mirror Notion so experienced users feel at home. One important flow is embedding content: the user types “/image” to upload an image, or “/code” to insert a code block, etc. We’ll handle those dialogues (file picker for images, etc.). The UI for embedded items (like an image) will allow resizing or open on click. Another key editing flow is linking: typing “@” or “\[\[” brings up a list of pages to link; the user selects one and it becomes a page link. This encourages building a network of notes easily. We will ensure these flows are smooth (no lag in pulling up the list of pages – might use prefetching or indexing to speed it up). Essentially, editing should feel like a fluid composing experience, not requiring any trips to settings or page reloads. Our local-first approach means even if you lose internet, nothing changes in this flow – which is a big win over Notion’s cloud editor. Semantic Search (Information Retrieval): When a user wants to find something, they can click the search bar (likely at the top of the sidebar or a hotkey like Ctrl+P or Ctrl+F for global search). The search UI will allow typing free-form queries. As the user types, we’ll show results in a dropdown or a dedicated search page. Traditional keyword matches appear, but importantly, we will show semantic results: for example, if the user types a question or a concept, we might display results even if exact words don’t match, possibly with a snippet or summary of relevance. The UI might label these results as “AI search results” or similar. We could also have an AI answer directly shown at the top – e.g., “Q: How do I configure X? A: According to your docs, you need to do Y…【source】” where source links to the page. This is a more advanced flow, but even at MVP, semantic search might simply rank the results by semantic relevance. The user can click a result to open that page, or preview it (maybe hover to see a preview snippet). A nice touch: highlight the matched text or context when the page opens (scroll to it), so the user sees why it was relevant – that’s something even Notion doesn’t do yet. Overall, search should feel like a powerful assistant rather than just a text finder. We’ll likely iterate on this a lot as it’s an AI showcase. But we’ll maintain a straightforward UI (a list of results, each with page title, maybe an excerpt). Speed is key – we’ll pre-index content so that search across even hundreds of pages is near-instant. AI Prompt Assistant Usage: Integrating AI into the UI needs careful design to be both discoverable and non-intrusive. We envision a few flows: Inline AI Actions: When a user highlights a portion of text or a whole block, a small tooltip or context menu offers options like “Summarize”, “Rewrite”, “Expand”, etc. For example, in AFFiNE’s demo, selecting text shows an “Ask AI” button\[35\] – we can do similar. Clicking it would generate a summary or explanation and either show it inline (perhaps as a collapsible block below the text) or copy it to clipboard/show in a modal. This allows users to get AI help in context. The design must ensure the button isn’t annoying – maybe it appears only on selection and is a small icon. Assistant Panel (Chat interface): We can have a button or sidebar for a “Chat with AI” feature. Clicking an “AI Assistant” button (maybe in top bar or sidebar) opens a panel where the user can type any question. The assistant can answer using the knowledge base content. For instance, user asks “Summarize all notes about project Alpha,” the assistant would search the notes and produce a summary, citing specific pages (we will have it reference pages so user trusts it). The UI here is like a chat window: user query, AI answer (with sources linked). The user can continue asking follow-ups. This transforms how users retrieve info – instead of manually searching and reading, they get synthesized answers. We need to show sources to maintain trust, so each answer might end with small links to the pages it drew from (like “from Page X”). This panel can be docked on the right side, so the user can see an answer while also looking at/editing a page on the left. Slash Commands for AI: Users could invoke AI via commands in the editor. For instance, typing /summarize on an empty block could create a summary of the current page’s content right there. Or /brainstorm could generate ideas below. These are quick one-off uses embedded in the content. The UI just treats them as commands; behind the scenes it runs the AI and then inserts the result as new blocks (possibly styled differently or with an icon to denote AI-generated). This is advanced usage but very powerful for those who want to, say, generate a draft from bullet points. In all these flows, feedback and control are crucial. If AI is working (which may take a couple seconds for a big request), we’ll show a loading indicator (like a typing dots animation, or a ghost text placeholder) so the user knows something’s happening. If it fails (network error), we’ll notify gracefully. We’ll also allow the user to cancel or stop generation if it’s long. We intend to put the user in control: AI suggestions are just that – suggestions. They can accept, edit, or ignore them. The UI will never overwrite user content without confirmation. We also won’t spam the user with AI if they don’t ask for it. It’s integrated, but at the user’s command, except possibly some subtle proactive suggestions (like maybe the search bar could faintly show “Ask anything…” to hint you can ask natural language). By designing these flows carefully, we ensure AI features actually enhance the UX rather than confuse it. For example, showing an inline “Summarize” on selection (as AFFiNE does) immediately communicates the capability in context\[35\] without the user reading docs. Similarly, a chat panel with a friendly prompt like “How can I help you?” invites usage. Sharing and Collaboration Flow: (Future) As part of virality, but also UX: if a user wants to share a page, the flow might be clicking a “Share” button on that page, then choosing “Copy web link” or “Invite collaborators”. This would tie into backend but from a UX standpoint we’ll have a modal for share settings (similar to Google Docs/Notion “Share” dialog). They can set read/edit rights if on server. If local, perhaps the share button would prompt to export or publish via some method. While not MVP-critical, it’s a flow we’ll design to be straightforward (because if it’s too hard to share, people won’t, hurting virality). Ideally, one click copying a link that either goes through our optional cloud or at least provides the content in some shareable form. Layout: Navigation, Sidebar & Drag-and-Drop We will adopt a familiar three-pane layout: a left sidebar for navigation, a main content area for the current page, and optionally a right sidebar for additional context (which could be toggled for things like page info, comments, or the AI/chat panel). Sidebar Navigation: The left sidebar will list the user’s top-level spaces or notebooks. For instance, it might have a section for “Work” and “Personal” (which could correspond to workspaces or categories). Under each, the pages hierarchy is shown (indentation for sub-pages). This is much like Notion’s workspace sidebar or Outline’s collection list. The user can collapse sections to keep it tidy. There will also be a quick access area for Favorites or Recent pages. Possibly also a search field at the top or a separate search button. The sidebar provides a structural overview at a glance. We’ll allow drag-and-drop in the sidebar to reorder pages or move them into/out of sections (with visual feedback like a highlight line). Right-clicking a page in sidebar brings up context menu (rename, delete, duplicate, etc.). The sidebar can be resized (user can drag its edge) and can auto-hide on smaller screens (with a hamburger menu to open it). This design ensures that even as your knowledge base grows, you have a mental map of it via the sidebar. It’s a proven layout for note apps, so we stick with it. Breadcrumbs & Page Header: At the top of the content area, we will show a breadcrumb path if the page is nested. For example, “Project Alpha / Meeting Notes / 2025-12-29” indicating this page’s lineage. Each segment is clickable to navigate up. This helps orientation and quick jumping between related pages. On the right side of the header, we might have some page-level actions (like star/favorite, share, toggle page view type if it’s a database). If the user is on a database page, maybe the header also includes a view switch (table, board, etc.). Keeping a consistent header with page title (editable inline) and breadcrumbs ensures the user always knows context. Notion does similar breadcrumbs for sub-pages, and it’s useful; we’ll likely mimic that. Content Layout & Blocks: The content area uses the full width (with some max width for readability in the case of long text, but if the user has wider content like images or boards, it can expand). Blocks are stacked vertically. We will show subtle horizontal rules or spacing to separate top-level blocks if needed, but mostly rely on whitespace. When a block or page is active/selected, we can highlight it or show its drag handle to indicate focus. There should also be a way to open a page as a full-page or as a sub-page in context. For example, in Notion you can either navigate into a sub-page or open it as a modal on top; we could allow Shift+Click to open a page in a modal view or side-by-side. This could be a later enhancement though. The editing toolbar can float near the top of the content area or near selected text, as previously noted. Drag-and-Drop: We support dragging blocks within a page to reorder – that will be by grabbing the drag handle (or perhaps alt+drag anywhere on block). We’ll show a line as a drop target. For dragging to another page, the user can drag a block over to the sidebar and drop it on a different page (which might either move it as a sub-page or copy it – we need to decide the logical behavior, likely moving as sub-page if dropped on a page name). The entire page can be dragged in sidebar to reorder under a different parent or section. A nice detail: if dragging in the sidebar near top or bottom, auto-scroll so you can move a page far in the list. Similarly, maybe allow dragging an image from your file system into a page to add it (that’s a common intuitive action). We will ensure drag-and-drop feels smooth: using ghost previews of the dragged item, clear indications where it will land. If a drop is invalid (like dragging a top-level page into a page of another workspace, maybe that’s fine actually, not many invalid cases except dragging something onto itself), we’ll handle accordingly. Multi-Window or Tabs: Possibly in future, allow opening multiple pages at once (maybe via browser tabs if web, or a tabbed interface in app). MVP likely single-page-at-a-time in UI to keep it simple, but we’ll design it such that if user opens a second window (especially in desktop app, could allow multiple windows) it still syncs state via the local CRDT. Global Navigation Elements: We might have a top bar that contains a menu icon (for mobile to open sidebar), the search bar, perhaps a toggle for light/dark mode, and a user account menu (especially if logged in to a server, it might show user’s name, settings, logout). On desktop offline mode, user account might just be local profile settings. We’ll keep the top bar minimal though – possibly just an icon for sidebar (if collapsed), the project name, and search. Many modern apps even hide the top bar when not needed. But since search is important, likely a top search input or button will persist. The responsive design will adapt this layout: on narrow screens (tablet/mobile), the sidebar becomes a slide-out drawer rather than always visible. The content would probably go edge-to-edge. Buttons become larger touch-friendly. We’ll test common breakpoints to ensure it’s usable on an iPad or phone in view mode. Integrating AI Features into the UI We touched on this in flows, but to summarize integration points: - Inline “Ask AI” Buttons: When text is selected or maybe when a block is hovered (we need to decide trigger), an AI option will appear. For instance, highlight a paragraph and a small floating tooltip says “✏️ Rewrite” or “💡 Summarize”. If clicked, the AI’s output could replace the text (for rewrite) or insert below (for summary) – after confirming with the user. The design of that tooltip should be subtle (perhaps a small icon that appears after 0.5s of selection so it’s not in your face). We might also add an AI icon in the block toolbar (if we have a persistent toolbar on the side of a block that usually has drag, delete, etc., one icon could be AI actions menu). - Slash Command Integration: Our slash command menu will list not just static block types but dynamic AI actions. For example, if the user types “/summarize”, the menu can show an entry like “Summarize this page (AI)” – selecting it triggers the action. Similarly “/continue writing” could take the current paragraph and extend it. These are intuitive because power users often try typing slash then some guess – we’ll make sure popular ones are covered. - AI Assistant Sidebar: A dedicated UI component for chatting or asking questions. We might use an icon, say a chatbot face or a magic wand, in the top bar or bottom corner – clicking it toggles the assistant panel. When open, it slides over or occupies a portion of the screen. The panel shows conversation history with the assistant. The user can type at the bottom (with an input box possibly containing placeholder “Ask me anything about your knowledge base…” to prompt usage). When the assistant responds, if it references content, we’ll hyperlink those references. Perhaps we also allow inserting the answer into the current page with a click if the user wants to save it (especially for summarizations). The presence of this panel should be optional; users not interested can ignore the button. But for those who use it, it becomes a powerful co-pilot while navigating content. - AI Feedback and Controls: We might include a quick way to adjust AI settings like tone or creativity level – maybe in a settings menu or when the assistant is open, a gear icon for “AI Settings”. This would let advanced users tweak things like “prefer shorter answers” or “use a different model/API”. We likely won’t expose much at MVP, but designing a spot for it ensures we don’t clutter the main UI later with such controls. - Visual Identity: We should give the AI some visual identity (without overdoing it). For example, responses in the chat could have a background color or an icon to indicate “AI wrote this”. Similarly, any AI-generated text inserted could be initially highlighted or labeled (so users know it’s machine-generated). This transparency is good UX and also helps users trust the tool (no hidden AI manipulation). A subtle “\[AI\]” label or icon next to an inserted summary could suffice, possibly removable after user accepts it. - Error Handling: If an AI request fails (due to no connection or API error), the UI should show a polite error message in context (like in the chat: “Oops, I couldn’t contact the AI service. Check your connection or API key.”) rather than silently failing. The user could retry easily (maybe a retry button). This is part of integrating AI smoothly – treat it as any other feature with proper feedback loops. By weaving AI into the UI at these touchpoints, we achieve an AI-native feel. The user doesn’t have to go out of their normal workflow to get AI help; it’s right there at the point of need (selecting text, searching, etc.). At the same time, we avoid bombarding the user with AI suggestions when not wanted – it’s a supportive role, invoked by the user. This balanced integration should make the features actually useful rather than gimmicky. One real example to illustrate integration: the screenshot below shows AFFiNE’s approach to inline AI assistance – the user selects text and an “Ask AI” option appears, allowing quick AI interaction within the note . We will adopt similar in-context triggers so that using AI feels as natural as formatting text. Our UI design around these will learn from any UX feedback on AFFiNE’s implementation to ensure it is smooth and does not annoy users. Example of an inline AI assist feature in a Notion-like editor. When users highlight text, they can invoke an AI helper (as shown above in AFFiNE’s interface with an “Ask AI” prompt). Our application will offer similar inline AI actions – e.g., summarizing or rewriting content – seamlessly within the editor. Mobile/Responsive Design and Dark Mode Even though our initial focus isn’t a native mobile app, we will implement responsive design so the app is usable on smaller screens: - Responsive Layout: On a tablet or phone, the interface will adjust – the sidebar becomes hidden behind a menu. The top bar might compress to just a menu button, a logo, and a search icon. Content will reflow to use larger font sizes for readability on mobile. Interactive elements will have sufficient touch target size (at least ~44px). We’ll test key flows on mobile browsers, like adding a note or checking off a to-do, to ensure it’s not painfully cramped. The editor itself may switch to a mobile-friendly editing mode (e.g., showing a toolbar at bottom for formatting, similar to how Notion on mobile works). - Mobile Editing Considerations: Some interactions like drag-and-drop are harder on touch. So on mobile, we might disable drag handles and instead provide alternate means (like a “Move up/down” small button on a block or long-press to pick up and then drag). Or simply document that complex rearrangements are easier on desktop for now. Scrolling and selecting text also is different on mobile; we’ll leverage the device’s native text selection where possible. We will likely hide the AI inline button on mobile by default (to not conflict with the native copy/paste handle popups), and maybe instead have an “AI” option in a long-press context menu or a small floating button that appears after selection differently. - Dark Mode: We will provide a polished dark theme from day one. Many knowledge workers prefer dark mode for reduced eye strain. Our design will specify color variables for light and dark, and we can switch based on user preference or system setting (via CSS prefers-color-scheme). Dark mode will use true blacks/dark-grays for background, with text in light gray/off-white (ensuring contrast). We’ll also adjust things like shadows or outlines to suit dark background. Icons and images should invert or have alternatives if needed (or we design them to be multi-theme friendly). We’ll let the user toggle it in settings or quick menu. We should also consider a high-contrast mode or custom themes, but light/dark is the main priority. We’ll test dark mode thoroughly so that every component is legible (e.g., no dark text on dark background issues). - Cross-Device Sync UI: (Not exactly UI, but design consideration) If a user uses both mobile and desktop, we should ensure a consistent experience. For example, if they use the web app on their phone and desktop app on PC, the interface and terminology is consistent, though layout differs. This reduces cognitive load switching contexts. - Touch & Gesture Support: On mobile, maybe allow swipe gestures – e.g., swipe right on a block to indent it (if we have outlines), or swipe in from left edge to open sidebar. We can utilize standard mobile patterns so it feels like a native app. We’ll also ensure things like tapping on a page link works (maybe with a slight delay vs. selection, because on desktop a single click opens link, on mobile a tap might also bring up keyboard selection – we manage these carefully). - Testing on Devices: We’ll gather feedback from using it on an actual phone browser early on. If something is very tedious (like editing a table on mobile), we might restrict that (maybe make tables read-only on very small screens initially, with a prompt “please use larger device to edit this” – not great, but realistic if it’s too hard to make usable). In the long run, we do plan native mobile apps (which could reuse the responsive web code via something like Capacitor or a rewrite). By implementing responsive design now, we pave the way for those with minimal rework. It also immediately benefits any user who quickly opens their notes on the phone. Dark mode, similarly, is not just cosmetic – a lot of users treat it as a must-have nowadays. We’ll design it with equal care as light mode, possibly even making it the default if system is dark. And we’ll avoid colors that cause eye strain (like pure white on pure black can be high contrast, we might use slightly softened whites). We’ll also check that our charts or code blocks look okay in dark mode (e.g., code syntax highlighting might need a different theme in dark). We may include a theme toggle in a convenient spot (like bottom of sidebar or in user menu). Some apps auto-change with OS, but giving user manual control is nice especially in a web context. Accessibility & UI Contribution Guidelines Accessibility is a top-tier requirement, not an afterthought. We will follow these practices: - Semantic HTML: Use correct HTML elements for structure. Our editor content will ultimately be HTML in the DOM. We will ensure headings in content use heading tags, lists use list tags, tables use etc., so that screen readers can interpret the structure of a page. The app container itself will have landmarks (e.g.,

for sidebar,

for content, etc.). For any custom widget (like a toolbar or menu), we’ll add appropriate ARIA roles (e.g., role="menuitem", aria-expanded on toggle buttons, etc.). - Keyboard Navigation: We’ll map out a tab order that makes sense: probably the top bar items first, then sidebar, then main content. Within the content (editor), arrow keys and tab will navigate blocks (like arrow down goes to next block, tab indents a list item, etc., consistent with text editor norms). We will support common shortcuts for accessibility, like pressing Alt+Shift+F10 (screen reader users do this to open context menu sometimes) or ESC to exit modals. Testing with screen reader (NVDA/JAWS or VoiceOver) will be on our checklist. For instance, when the user focuses on the editor, the screen reader should announce the title and content, and be able to read through. It’s tricky with complex editors, but we might provide a simplified view for screen readers (like a toggle to raw Markdown maybe) if needed. Nonetheless, we’ll attempt to make the WYSIWYG itself navigable (ProseMirror has some ARIA practices we can adopt). - Color and Contrast: All text and iconography will meet contrast guidelines (4.5:1 for normal text, etc.). We’ll avoid conveying information by color alone (if we color-code something, we also use an icon or label). We’ll have a mode or check for color-blind friendliness if we use any charts or status colors (like ensure red/green differences are also shape or pattern differences). - Animations: Avoid overly flashy or distracting animations, and respect a user’s “reduce motion” preference (CSS prefers-reduced-motion). If someone has that, we’ll disable non-essential animations (like maybe the block drag animation). - Accessible Forms/Controls: Any input or setting in the UI will have a label. If we use icon-only buttons, they will have aria-label attributes so screen reader can say what it does (e.g., the AI icon button might have aria-label="Open AI Assistant Chat"). - Testing & Iteration: We will include accessibility testing in our QA. Possibly use automated tools like axe to catch basic issues. But also manual testing with keyboard and screen reader to ensure flows can be completed without a mouse or sight. - Guidelines for Contributors: In our contribution docs, we’ll have a section on UI contributions stating that any new UI element must be accessible. For example, if a contributor adds a new button or dialog, they should follow the patterns we have (we might create a small library of common components, like accessible dialog component, accessible dropdown etc., to use consistently). We’ll review PRs with an eye on accessibility and ask for fixes if something lacks (e.g., missing focus state or alt text). - Focus Management: When modals open, we’ll trap focus inside them (so keyboard doesn’t accidentally go to background). When modals close, return focus to a sensible place. This kind of polish we’ll implement via either our UI library or custom code. - Documentation: We’ll document keyboard shortcuts and any special accessibility features in the user guide, so users who rely on those know what’s available. Possibly create a “Keyboard Shortcuts Cheat Sheet” available within the app (like pressing ? could bring it up). - User Preferences: Offer settings like font size adjustments or maybe different fonts (some users with dyslexia prefer certain fonts, etc.). Not MVP but we consider it. At least ensure the app works if user applies browser-level zoom (should scale gracefully). Accessibility work not only helps disabled users but often improves general UX (clear labels, logical focus order, etc., benefit everyone). We want our app to be usable by as many people as possible – it fits with our open/community ethos. In conclusion, our UX/UI design is about creating a comfortable, empowering environment for managing knowledge. It takes cues from familiar tools to lower the learning curve, and then pushes forward with built-in AI and a snappy local experience to feel like something new and exciting. Every design decision will be filtered through “does this make the user’s life easier or harder?”. We’ll gather user feedback continuously and iterate, since a great UX is never done – but the principles above will guide us to hit the ground running with a strong initial design that avoids known pitfalls of competitors\[19\]\[21\] and sets the stage for a truly next-generation knowledge base. Sources: Ankush Das. “5 Privacy-Focused Notion Alternatives That I Tried!” It’s FOSS – notes on AFFiNE and AppFlowy features\[11\]\[15\], including AFFiNE’s local-first approach and AppFlowy’s offline mode. Reddit discussion on open-source Notion alternatives – user feedback about AFFiNE being immature and AppFlowy lacking nested pages\[13\], Outline being smooth but web-only\[18\], and Anytype’s p2p sync model\[34\]. AFFiNE Blog. “Why AFFiNE Chose CRDT over OT…” – highlights benefits of CRDT for decentralization and enabling local-first collaboration\[22\]. Costa Alexoglou. “Tauri vs. Electron: performance, bundle size, and the real trade-offs” (2025) – shows Tauri’s much smaller memory and bundle size vs Electron\[23\]\[24\]. AppFlowy Blog. “How we built AppFlowy with Flutter and Rust” – describes AppFlowy’s values of data privacy, native experience, and extensibility\[36\]. Hacker News comments on Outline – note on Outline’s friction (publish step, lack of quick page creation) and licensing issues (BSL license)\[37\]\[10\]. It’s FOSS article – notes AFFiNE’s missing mobile apps and integration features\[4\], Logseq’s learning curve\[21\], etc., which informed our decisions to prioritize ease-of-use and mobile later. \[1\] \[13\] \[14\] \[17\] \[18\] \[34\] Notion alternative: AppFlowy vs Outline vs Affine? : r/selfhosted https://www.reddit.com/r/selfhosted/comments/14s9d8j/notion\_alternative\_appflowy\_vs\_outline\_vs\_affine/ \[2\] \[4\] \[5\] \[6\] \[7\] \[11\] \[12\] \[15\] \[16\] \[21\] \[33\] \[35\] 5 Privacy-Focused Notion Alternatives That I Tried! https://itsfoss.com/notion-alternatives/ \[3\] \[28\] \[29\] \[30\] \[36\] How we built Appflowy with Flutter and Rust https://appflowy.com/blog/tech-design-flutter-rust \[8\] Escape Information Overload: Smarter Notion Alternatives | AFFiNE https://affine.pro/blog/best-notion-alternatives \[9\] \[10\] \[19\] \[37\] Outline: Self hostable, realtime, Markdown compatible knowledge base | Hacker News https://news.ycombinator.com/item?id=39012054 \[20\] \[31\] \[32\] GitHub - outline/outline: The fastest knowledge base for growing teams. Beautiful, realtime collaborative, feature packed, and markdown compatible. https://github.com/outline/outline \[22\] \[25\] \[26\] \[27\] Why AFFiNE Chose CRDT over OT to Build a Collaborative Editor | AFFiNE https://affine.pro/blog/why-affine-chose-crdt-over-ot-to-build-a-collaborative-editor \[23\] \[24\] Tauri vs. Electron: performance, bundle size, and the real trade-offs https://www.gethopp.app/blog/tauri-vs-electron